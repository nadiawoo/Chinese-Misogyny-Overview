# -*- coding: utf-8 -*-
"""LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12YA-pQH5WIumtMLeBV7P4Uu2io0T2w_f
"""

!pip install cpm_kernels transformers==4.27.1 accelerate -q

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

from transformers import AutoTokenizer, AutoModel

model_name = "THUDM/chatglm-6b-int4"

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name, trust_remote_code=True).half().cuda()
model.eval()

response, history = model.chat(tokenizer, "你好", history=[])
print(response)

df = pd.read_csv("llm_train.csv").dropna(subset=["text"]).reset_index()

import pandas as pd
import os
from tqdm import tqdm

texts = df["text"].tolist()

save_path = "chatglm_predictions_labels_only.csv"
if os.path.exists(save_path):
    df_saved = pd.read_csv(save_path)
    processed_ids = set(df_saved["index"])
else:
    df_saved = pd.DataFrame(columns=["index", "text", "label"])
    processed_ids = set()

def classify_post_label_only(model, tokenizer, post):
    prompt = (
        "你是一个微博内容审核助手。\n"
        "请判断下列微博是否包含对女性的贬低、歧视或仇恨内容。\n"
        "如果文字是为了保护女性、批评歧视、表达平权观点，请回答“0”。\n"
        "若文字包含贬低、侮辱、嘲笑、物化女性，或带有性别偏见，请回答“1”。\n"
        "请只回答“0”或“1”。"
    )

    full_prompt = f"{prompt}\n\n微博内容：{post}\n是否为性别歧视内容？"
    response, _ = model.chat(tokenizer, full_prompt, history=[])
    result = response.strip()

    if result.startswith("1"):
        return "1", result
    elif result.startswith("0"):
        return "0", result
    elif "1" in result and "0" not in result:
        return "1", result
    elif "0" in result:
        return "0", result
    else:
        return "未知", result

batch_size = 10
records = []

for i in tqdm(range(len(texts))):
    idx = df.loc[i, "index"]
    if idx in processed_ids:
        continue

    text = texts[i]
    try:
        label, raw = classify_post_label_only(model, tokenizer, text)
        records.append({
            "index": idx,
            "text": text,
            "label": label
        })

        if len(records) >= batch_size:
            df_new = pd.DataFrame(records)
            df_saved = pd.concat([df_saved, df_new], ignore_index=True)
            df_saved.to_csv(save_path, index=False)
            records = []

    except Exception as e:
        print(f"Error at index {idx}: {e}")
        continue

if records:
    df_new = pd.DataFrame(records)
    df_saved = pd.concat([df_saved, df_new], ignore_index=True)
    df_saved.to_csv(save_path, index=False)

print("All posts classified and saved to:", save_path)

records

df_new = pd.DataFrame(records)
    df_saved = pd.concat([df_saved, df_new], ignore_index=True)
    df_saved.to_csv(save_path, index=False)

df_saved.to_csv('llm_df.csv', index=False)

llm_labeled = pd.read_csv('/content/llm_df.csv')
llm_labeled = llm_labeled[['text', 'label']]
llm_labeled = llm_labeled.rename(columns={'label': 'llm_label'})

eval_df = pd.read_csv('/content/llm_train.csv')
eval_df = eval_df[['text', 'label']]
eval_df = eval_df.rename(columns={'label': 'true_label'})

llm_labeled.head()

llm_labeled['llm_label'].unique()

import numpy as np
llm_labeled['llm_label'].replace('未知', np.nan, inplace=True)
llm_labeled = llm_labeled.dropna()

llm_labeled['llm_label'].astype(int)

(llm_labeled['llm_label'].astype(int) == 1).sum() / len(llm_labeled) * 100
#doesnt seem the most accurate

eval_df.head()

df_merged = pd.merge(eval_df, llm_labeled, on='text', how='left')
df_merged = df_merged.dropna()

import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix

df_merged["true_label"] = df_merged["true_label"].astype(int)
df_merged["llm_label"] = df_merged["llm_label"].astype(int)

report = classification_report(df_merged["true_label"], df_merged["llm_label"], output_dict=True)
conf_matrix = confusion_matrix(df_merged["true_label"], df_merged["llm_label"])
report_df = pd.DataFrame(report).transpose()
report_df["support"] = report_df["support"].astype(int)

report_df #this is using LLM ChatGLM6B

llm_labeled

